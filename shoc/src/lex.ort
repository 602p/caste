import linkedlist

function() lex::get_alphabet -> cstr does
return "qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM_"

function() lex::get_ext_identifier -> cstr does
return "qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM_1234567890"

function(cstr text) lex::match_identifier -> int does
	if -((text[0]):in(lex::get_alphabet())) do
		return 0
	done

	int i=1
	while text[i]:in(lex::get_ext_identifier()) & (i<text:len()) do
		i+=1
	done
return i

function(cstr text) lex::match_function_identifier -> int does
	if -((text[0]):in(lex::get_alphabet())) do
		return 0
	done

	int i=1
	while (text[i]:in(lex::get_ext_identifier()) + text[i]:in(":")) & (i<text:len()) do
		i+=1
	done
return i

function(cstr text) lex::match_binop -> int does
	if text:startswith("==") +\
	   text:startswith("!=") +\
	   text:startswith(">=") +\
	   text:startswith("<=") +\
	   text:startswith(">>") +\
	   text:startswith("<<") do
	   	return 2
	done
return text[0]:in("&*/-+%<>")|int

function(cstr text) lex::match_augassign -> int does
	if text:startswith("+=") +\
	   text:startswith("-=") +\
	   text:startswith("*=") +\
	   text:startswith("/=") do
	   	return 2
	done
return 0

function(cstr text) lex::match_int_literal -> int does
	if -text[0]:in("1234567890") do
		return 0
	done
	int i=0
	while text[i]:in("1234567890xbXB") do
		i+=1
	done
	if text[i]:in(".") do
		return 0
	done
return i

function(cstr text) lex::match_float_literal -> int does
	int i=0
	while text[i]:in("1234567890.") do
		i+=1
	done

	if i==1 do #Don't match '.'
		return 0
	done
return i

function(cstr text) lex::match_var_decl -> int does
	int i = lex::match_identifier(text)

	if i==0 do
		return 0
	done

	while text[i]:in(" \t") do
		i+=1
	done

	int name=lex::match_identifier(text:offset(i))

	if name==0 do
		return 0
	done

	i+=name
return i

function(cstr text) lex::match_string_literal -> int does
	#I've got a bug in my first-gen compiler actaully, where "\"" isn't a valid string...
	#hahahaha... that's actually not a problem in this compiler (SHOC) but i have to do
	#this hack to get SHOC to compile in orthc
	if -(text[0]==34|byte) do
		return 0
	done

	int i=1
	bool escape=false
	bool continue=true
	while continue do
		if ((text[i]==34|byte) & -escape) do
			continue=false
		done

		if text[i]:in("\\") & -escape do
			escape=true
		else do
			escape=false
		done

		i+=1
	done
return i

function(cstr text) lex::match_line_comment -> int does
	if -text[0]:in("#") do
		return 0
	done

	int i=1
	while -text[i]:in("\r\n") do
		i+=1
	done
return i

function(cstr text) lex::match_block_comment -> int does
	if -text:startswith("<#") do
		return 0
	done

	int i=1
	while -text:offset(i):startswith("#>") do
		i+=1
	done
return i

function(cstr text) lex::match_import -> int does
	if -text:startswith("import ") do
		return 0
	done

	int i="import":len()
	while text[i]:in(" \t") do
		i+=1
	done

	while -text[i]:in(" \r\n\t") do
		i+=1
	done
return i

function(cstr text) lex::match_intrinsic -> int does
	if -text[0]:in("@") do
		return 0
	done

	int i=1
	while -text[i]:in("@") do
		i+=1
	done
	i+=1
return i

type TokenMatcher is a function->int
type TokenType is
	cstr name
	int simple_type
	# 0 = Matcher Function
	# 1 = text[0] in simple_text
	# 2 = test:startswith(simple_text)
	# 3 = test:startswith(simple_text) and followed by whitespace (keyword)
	cstr simple_text
	TokenMatcher func
	List preceeded_opts
	bool produce_token

	function(cstr name, TokenMatcher func) TokenType::new_fn -> TokenType does
		TokenType new = malloc(@sizeof(TokenType)@)|TokenType
		new.name=name
		new.simple_type=0
		new.func=func
		new.preceeded_opts=null|List
		new.produce_token=true
	return new

	function(cstr name, cstr text) TokenType::new_in -> TokenType does
		TokenType new = TokenType::new_fn(name, null|TokenMatcher)
		new.simple_type=1
		new.simple_text=text
	return new

	function(cstr name, cstr text) TokenType::new_eq -> TokenType does
		TokenType new = TokenType::new_in(name, text)
		new.simple_type=2
	return new

	function(cstr name, cstr text) TokenType::new_kw -> TokenType does
		TokenType new = TokenType::new_in(name, text)
		new.simple_type=3
	return new

	function(TokenType self, cstr text) TokenType:match_internal -> int does
		if self.simple_type==1 do
			return text[0]:in(self.simple_text)|int
		elif self.simple_type==2 do
			if text:startswith(self.simple_text) do
				return self.simple_text:len()
			done
			return 0
		elif self.simple_type==3 do
			if text:startswith(self.simple_text) do
				if text[self.simple_text:len()]:in(" \t\r\n") do
					return self.simple_text:len()
				done
				return 0
			done
			return 0
		done
	return self.func(text)

	function(TokenType self, List token_context, cstr text) TokenType:match -> int does
		int count = self:match_internal(text)
		if self.preceeded_opts|ptr!=null do
			TokenType last_type = (token_context:get(token_context.len-1)|Token).type_
			int opts_pos=0
			while opts_pos<self.preceeded_opts.len do
				if last_type.name==self.preceeded_opts:get(opts_pos)|cstr do
					return count
				done
				opts_pos+=1
			done
		else do
			return count
		done
	return 0

	function(TokenType self, cstr prev_req) TokenType:after -> TokenType does
		if self.preceeded_opts|ptr == null do
			self.preceeded_opts=List::new()
		done
		self.preceeded_opts:append(prev_req|ptr)
	return self

	function(TokenType self, cstr prev_req) TokenType:or -> TokenType does
	return self:after(prev_req)

	function(TokenType self) TokenType:free -> void does
		if self.preceeded_opts|ptr!=null do
			self.preceeded_opts:clear()
			self.preceeded_opts:free()
		done
		free(self|ptr)
	return

	function(TokenType self, TokenType other) TokenType:__eq__ -> bool does
	return self.name==other.name

	function(TokenType self) TokenType:notoken -> TokenType does
		self.produce_token=false
	return self

	function(TokenType self, cstr text) TokenType:make_token -> Token does
	return Token::_new(text:substr(0, self:match_internal(text)), self)
endtype

type Token is
	cstr text
	TokenType type_
	cstr origin_file #TODO
	int origin_line #TODO

	function(cstr text, TokenType type_) Token::_new -> Token does
		Token new = malloc(@sizeof(Token)@)|Token
		new.text=text
		new.type_=type_
	return new

	function(Token self) Token:free -> void does
		#free(self.text|ptr)
		free(self|ptr)
	return

	function(List l) Token::free_token_list -> void does
		while l.len>0 do
			(l:get(0)|Token):free()
			l:del(0)
		done
		l:clear()
		l:free()
	return
endtype

List lex_token_types

function() lex::init -> void does
	List t=List::new()

	t:append(TokenType::new_fn("T_LINE_COMMENT", lex::match_line_comment|TokenMatcher):notoken()|ptr)
	t:append(TokenType::new_fn("T_BLOCK_COMMENT", lex::match_block_comment|TokenMatcher):notoken()|ptr)

	t:append(TokenType::new_fn("T_IMPORT", lex::match_import|TokenMatcher)|ptr)
	t:append(TokenType::new_fn("T_INTRINSIC", lex::match_intrinsic|TokenMatcher)|ptr)

	t:append(TokenType::new_kw("T_IF", "if")|ptr)
	t:append(TokenType::new_kw("T_DONE", "done")|ptr)
	t:append(TokenType::new_kw("T_DO", "do")|ptr)
	t:append(TokenType::new_kw("T_ELIF", "elif"):after("T_ENDOFSTATEMENT")|ptr)
	t:append(TokenType::new_kw("T_ELSE", "else"):after("T_ENDOFSTATEMENT")|ptr)

	t:append(TokenType::new_kw("T_RETURN", "return"):after("T_ENDOFSTATEMENT")|ptr)

	t:append(TokenType::new_kw("T_WHILE", "while"):after("T_ENDOFSTATEMENT")|ptr)

	t:append(TokenType::new_kw("T_TYPEDECL", "type")|ptr)
	t:append(TokenType::new_kw("T_TYPEDECL_IS", "is")|ptr)
	t:append(TokenType::new_fn("T_TYPEDECL_NAME", lex::match_identifier|TokenMatcher):after("T_TYPEDECL")|ptr)
	t:append(TokenType::new_kw("T_TYPEDECL_ENDTYPE", "do")|ptr)
	t:append(TokenType::new_kw("T_TYPEDECL_PACKED", "packed"):after("T_TYPEDECL_IS")|ptr)
	t:append(TokenType::new_kw("T_TYPEDECL_ALIAS", "a"):after("T_TYPEDECL_IS")|ptr)
	t:append(TokenType::new_eq("T_TYPEDECL_ALIAS_FUNC", "function->"):after("T_TYPEDECL_ALIAS")|ptr)
	t:append(TokenType::new_fn("T_TYPEDECL_ALIAS_FUNC_RT", lex::match_identifier|TokenMatcher):after("T_TYPEDECL_ALIAS_FUNC")|ptr)
	t:append(TokenType::new_fn("T_TYPEDECL_ALIAS_NAME", lex::match_identifier|TokenMatcher):after("T_TYPEDECL_ALIAS")|ptr)
	
	t:append(TokenType::new_eq("T_FUNCTIONDECL", "function"):after("T_ENDOFSTATEMENT")|ptr)
	t:append(TokenType::new_eq("T_ARGLIST_START", "("):after("T_FUNCTIONDECL")|ptr)
	t:append(TokenType::new_fn("T_ARGLIST_ELE", lex::match_var_decl|TokenMatcher):after("T_ARGLIST_START"):or("T_ARGLIST_SEP")|ptr)
	t:append(TokenType::new_eq("T_ARGLIST_SEP", ","):after("T_ARGLIST_ELE")|ptr)
	t:append(TokenType::new_eq("T_ARGLIST_END", ")"):after("T_ARGLIST_ELE"):or("T_ARGLIST_START")|ptr)
	t:append(TokenType::new_fn("T_FUNCTIONDECL_NAME", lex::match_function_identifier|TokenMatcher):after("T_ARGLIST_END")|ptr)
	t:append(TokenType::new_eq("T_FUNCTIONDECL_RETURN", "->"):after("T_FUNCTIONDECL_NAME")|ptr)
	t:append(TokenType::new_fn("T_FUNCTIONDECL_RETURN_TY", lex::match_identifier|TokenMatcher):after("T_FUNCTIONDECL_RETURN")|ptr)
	t:append(TokenType::new_kw("T_FUNCTIONDECL_DOES", "does"):after("T_FUNCTIONDECL_RETURN_TY")|ptr)

	t:append(TokenType::new_fn("T_VAR_DECL", lex::match_var_decl|TokenMatcher):after("T_ENDOFSTATEMENT")|ptr)
	t:append(TokenType::new_fn("T_NAME", lex::match_identifier|TokenMatcher)|ptr)

	t:append(TokenType::new_fn("T_INT_LITERAL", lex::match_int_literal|TokenMatcher)|ptr)
	t:append(TokenType::new_fn("T_FLOAT_LITERAL", lex::match_float_literal|TokenMatcher)|ptr)
	t:append(TokenType::new_fn("T_STRING_LITERAL", lex::match_string_literal|TokenMatcher)|ptr)

	t:append(TokenType::new_fn("T_AUGASSIGN", lex::match_augassign|TokenMatcher)|ptr)
	t:append(TokenType::new_fn("T_BINOP", lex::match_binop|TokenMatcher)\
		:after("T_NAME"):or("T_BRACKET_CLOSE"):or("T_PAREN_CLOSE"):or("T_INT_LITERAL")\
		:or("T_STRING_LITERAL"):or("T_FLOAT_LITERAL")|ptr) #Only match after things that could be value (removes
															#confustion with unary -)
	t:append(TokenType::new_eq("T_ASSIGN", "=")|ptr)
	

	t:append(TokenType::new_eq("T_PAREN_OPEN", "(")|ptr)
	t:append(TokenType::new_eq("T_PAREN_CLOSE", ")")|ptr)
	t:append(TokenType::new_eq("T_CAST", "|")|ptr)
	t:append(TokenType::new_eq("T_DOT", ".")|ptr)
	t:append(TokenType::new_eq("T_BRACKET_OPEN", "[")|ptr)
	t:append(TokenType::new_eq("T_BRACKET_CLOSE", "]")|ptr)
	t:append(TokenType::new_eq("T_DOT", ".")|ptr)
	t:append(TokenType::new_eq("T_COMMA", ",")|ptr)
	t:append(TokenType::new_eq("T_DOUBLECOLON", "::")|ptr)
	t:append(TokenType::new_eq("T_COLON", ":")|ptr)
	
	
	t:append(TokenType::new_in("T_UNOP", "-!")|ptr)
	
	t:append(TokenType::new_in("T_ENDOFSTATEMENT", "\r\n;")|ptr)

	lex_token_types=t
return

function(cstr name) lex::tokty_by_name -> TokenType does
	int i=0
	while i<lex_token_types.len do
		if (lex_token_types:get(i)|TokenType).name==name do
			return lex_token_types:get(i)|TokenType
		done
		i+=1
	done
return null|TokenType

function() lex::free -> void does
	while lex_token_types.len>0 do
		(lex_token_types:get(0)|TokenType):free()
		lex_token_types:del(0)
	done
	lex_token_types:clear()
	lex_token_types:free()
return

function(cstr text) lex::tokenize -> List does
	#text=text+"\n;;;"
	ProgressBar bar = ProgressBar::new(text:len(), 40, "Tokenizing...")
	int text_pos=0
	int current_matcher_idx
	TokenType current_matcher
	int dbg_print_token_pos
	int match_len
	bool matched
	List tokens = List::new()
	tokens:append(lex::tokty_by_name("T_ENDOFSTATEMENT"):make_token(";")|ptr)
	bool ok = true
	while (text_pos<text:len()) & ok do
		current_matcher_idx=0
		matched=false
		while (current_matcher_idx<lex_token_types.len) & (-matched) do
			current_matcher=lex_token_types:get(current_matcher_idx)|TokenType
			match_len=current_matcher:match(tokens, text:offset(text_pos))
			if match_len>0 do
				matched=true
				if current_matcher.produce_token do
					tokens:append(current_matcher:make_token(text:offset(text_pos))|ptr)
				done
				text_pos+=match_len
			done
			current_matcher_idx+=1
		done
		if text[text_pos]:in(" \t") do
			text_pos+=1
		elif text[text_pos]:in("\\") do
			text_pos+=1
			while text[text_pos]:in(" \t\r\n") do
				text_pos+=1
			done
		elif -matched do
			printf("E: can't match any furter after %i:`%s`\n", text_pos, text:offset(text_pos))
			ok=false
		done
		bar:update(text_pos)
	done
	#text:free()
	bar:free()
return tokens